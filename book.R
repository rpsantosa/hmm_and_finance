# 
# https://github.com/rpsantosa/hmm_and_finance.git
# git config remote.origin.url  git@github.com:rpsantosa/hmm_and_finance.git
# #git remote add origin git@github.com:rpsantosa/hmm_and_finance.git
# git push -u origin master

#https://www.r-bloggers.com/fun-with-r-and-hmms/
# temp <- tempfile()
# link<-'https://archive.org/download/BrownCorpus/brown.zip'
# download.file(link,temp)
# u<-unzip(temp)
# ###############################
# # library(readr)
# # mystring <- read_file(u[1] )
# ################################
# nfunc<-function(i,u){
#   corpus<-readChar(u[i],nchar=100000)
#   a <- unlist (strsplit (gsub ("[^a-z]", "_", tolower (corpus)), ""))
#   return(a)
# }
# a<-unlist(sapply(1:4,u,FUN=nfunc))
# 
# letter.labels=c("_", letters)

########################## with a more reasonable file#############
link<-'http://www.cs.toronto.edu/~gpenn/csc401/A1/Brown.tgz'
u<-gzfile('~/Downloads/Brown.tgz')
corpus<-readLines(u)
al<-gsub ("[A-R][0-9]{2}[ \t\r\n\v\f][0-9]{4}[ \t\r\n\v\f]+[0-9][ \t\r\n\v\f]+",
          "", corpus)
al<-tolower(gsub("[^A-Za-z0-9 ]",'',al))
a<-unlist(strsplit (gsub ("[^a-z]", "_", a), ""))
#
#### Same, but using %>% (elegant) 
# a<-corpus %>% 
# gsub ("[A-R][0-9]{2}[ \t\r\n\v\f][0-9]{4}[ \t\r\n\v\f]+[0-9][ \t\r\n\v\f]+","", .) %>%
# gsub("[^A-Za-z0-9 ]",'', .) %>%
# tolower %>%
# gsub ("[^a-z]", "_",.) %>%
# strsplit(.,"") %>% unlist




library (HMM)
library (lattice)
letter.labels=c("_", letters)
prob <- function (x) {x /sum(x)}  # Makes it a probability (it sums to 1)
hmm <- initHMM (c("A", "B"), letter.labels, startProbs=prob (runif (2)),
                transProbs= t(apply(matrix(runif (4), 2),2,prob)),
                emissionProbs= apply(matrix(runif (54),ncol=2),1,prob))

#Then, we use the Baum Welch algorithm to update the probabilities based on repeated iteration over the corpus:
  
  t1<-system.time (a.bw <- baumWelch (hmm, a[1:1e5]))
  system.time (a.vt <- viterbiTraining(hmm, a))

  #system.time (a.bw <- baumWelch (hmm, a, 5))
  #would iterate at most 5 times. The results wonâ€™t be nearly as good as going, say, 50 iterations but you should see one of the two classes having larger bumps at the vowels and space. The graph at the top of the article was generated by:
    xyplot (a.bw$hmm$emissionProbs[1,] ~ c(1:27), scales=list(x=list(at=1:27, labels=colnames (a.bw$hmm$emissionProbs))), type='h')
#  and the other state is:
    xyplot (a.bw$hmm$emissionProbs[2,] ~ c(1:27), scales=list(x=list(at=1:27, labels=colnames (a.bw$hmm$emissionProbs))), type='h')
    
    xyplot (a.vt$hmm$emissionProbs[1,] ~ c(1:27), scales=list(x=list(at=1:27, labels=colnames (a.vt$hmm$emissionProbs))), type='h')
    #  and the other state is:
    xyplot (a.vt$hmm$emissionProbs[2,] ~ c(1:27), scales=list(x=list(at=1:27, labels=colnames (a.vt$hmm$emissionProbs))), type='h')
  